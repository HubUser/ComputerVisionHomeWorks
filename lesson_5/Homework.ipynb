{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 5\n",
    "\n",
    "In this homework you are going to implement the **Floyd-Steinberg dithering** algorithm. Dithering, in general, means that we are adding noise to the signal (in our case digital image) in order to perceive it better. In other words, by adding the noise the objective quality will be worse but the subjective quality will be better (i.e. the image will \"look\" better).\n",
    "\n",
    "The details of FS dithering can be found in this [wiki](https://en.wikipedia.org/wiki/Floyd%E2%80%93Steinberg_dithering) page. In order to implement the dithering, we will implement the following steps:\n",
    "* Define colour pallette\n",
    "* Quantize the image to obtain the baseline and compute the average quantization error\n",
    "* Implement FS dithering and compute the average quantization error\n",
    "\n",
    "You will also have to answer the question at the end of this notebook.\n",
    "\n",
    "Note: In this homework, you will have the chance to earn some extra points. See the \"Bonus\" section at the end of the notebook. Good luck!\n",
    "\n",
    "As always, you are encouraged to use your own images :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = cv2.imread('./data/kodim23.png')\n",
    "# Convert it to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# Plot it\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with gray tones first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black, dark gray, light gray, white\n",
    "colors = np.array([[0, 0, 0],\n",
    "                   [64, 64, 64],\n",
    "                   [192, 192, 192],\n",
    "                   [255, 255, 255]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the colour pallette, let's quantize the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "\n",
    "\n",
    "# Prepare for quantization\n",
    "rows, cols, channels = img.shape\n",
    "\n",
    "# Apply quantization\n",
    "def apply_quantization_gray(pixel, palette):\n",
    "    pixel = pixel.astype(np.float32)\n",
    "    min_diff = np.inf\n",
    "    selected_color = None\n",
    "    \n",
    "    for c in palette:\n",
    "        gray = np.sqrt((pixel[0] ** 2 + pixel[1] ** 2 + pixel[2] ** 2) / 3)\n",
    "        diff_sq = (c[0] - gray) ** 2\n",
    "        if diff_sq < min_diff:\n",
    "            min_diff = diff_sq\n",
    "            selected_color = c\n",
    "\n",
    "    return selected_color\n",
    "\n",
    "quantize = ft.partial(apply_quantization_gray, palette=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized = np.apply_along_axis(quantize, 2, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show quantized image (don't forget to cast back to uint8)\n",
    "plt.imshow(quantized);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average quantization error\n",
    "rows, columns, _ = img.shape\n",
    "avg_quant_error = (img - quantized).sum() / (rows * columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.755650838216145\n"
     ]
    }
   ],
   "source": [
    "print(avg_quant_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Floyd-Steinberg Dithering\n",
    "We are now going to implement the FS dithering and compare it to the optimally quantized image we have calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a temporal copy of the original image, we will need it for error diffusion\n",
    "img_tmp = np.copy(img)\n",
    "dithering = np.zeros_like(img)\n",
    "\n",
    "\n",
    "def mix_error(pixel, error, k):\n",
    "    return np.clip(pixel + error * k, 0, 255)\n",
    "    \n",
    "\n",
    "for r in range(0, rows-1):\n",
    "    for c in range(1, cols-1):\n",
    "        # Extract the original pixel value\n",
    "        pixel = img_tmp[r, c, :]\n",
    "        # Find the closest colour from the pallette (using absolute value/Euclidean distance)\n",
    "        # Note: You may need more than one line of code here\n",
    "        new_pixel = quantize(pixel)\n",
    "        \n",
    "        # Compute quantization error\n",
    "        quant_error = pixel - new_pixel\n",
    "        \n",
    "        # Diffuse the quantization error accroding to the FS diffusion matrix\n",
    "        # Note: You may need more than one line of code here\n",
    "        img_tmp[r, c + 1] = mix_error(img_tmp[r, c + 1], quant_error, 7 / 16)\n",
    "        img_tmp[r + 1, c - 1] = mix_error(img_tmp[r + 1, c - 1], quant_error, 1 / 16)\n",
    "        img_tmp[r + 1, c] = mix_error(img_tmp[r + 1, c], quant_error, 3 / 16)\n",
    "        img_tmp[r + 1, c + 1] = mix_error(img_tmp[r + 1, c + 1], quant_error, 5 / 16)\n",
    "        \n",
    "        # Apply dithering\n",
    "        dithering[r, c, :] = new_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show quantized image (don't forget to cast back to uint8)\n",
    "plt.subplot(121), plt.imshow(quantized)   # optimally quantized\n",
    "plt.subplot(122), plt.imshow(dithering);   # dithering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average quantization error for dithered image\n",
    "avg_dith_error = avg_quant_error = (img - dithering).sum() / (rows * columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363.91185760498047\n"
     ]
    }
   ],
   "source": [
    "print(avg_dith_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* Which image has higher quantization error? Optimally quantized or dithered?\n",
    "* Which image looks better to you?\n",
    "* Can you repeat the same process using only two colours: black and white? Show me :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Which image has higher quantization error? Optimally quantized or dithered?\n",
    "\n",
    "Dithering image has higher quantization error\n",
    "\n",
    "> Which image looks better to you?\n",
    "\n",
    "Dithering image\n",
    "\n",
    "> Can you repeat the same process using only two colours: black and white? Show me :-)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dither_image(img, quantize_fn):\n",
    "    # Make a temporal copy of the original image, we will need it for error diffusion\n",
    "    img_tmp = np.copy(img)\n",
    "    dithering = np.zeros_like(img)\n",
    "    \n",
    "    for r in range(0, rows-1):\n",
    "        for c in range(1, cols-1):\n",
    "            # Extract the original pixel value\n",
    "            pixel = img_tmp[r, c]\n",
    "            # Find the closest colour from the pallette (using absolute value/Euclidean distance)\n",
    "            # Note: You may need more than one line of code here\n",
    "            new_pixel = quantize_fn(pixel)\n",
    "            \n",
    "            # Compute quantization error\n",
    "            quant_error = pixel - new_pixel\n",
    "            \n",
    "            # Diffuse the quantization error accroding to the FS diffusion matrix\n",
    "            # Note: You may need more than one line of code here\n",
    "            if (0 < r < rows - 1) and (0 < c < cols - 1): \n",
    "                img_tmp[r, c + 1] = mix_error(img_tmp[r, c + 1], quant_error, 7 / 16)\n",
    "                img_tmp[r + 1, c - 1] = mix_error(img_tmp[r + 1, c - 1], quant_error, 1 / 16)\n",
    "                img_tmp[r + 1, c] = mix_error(img_tmp[r + 1, c], quant_error, 3 / 16)\n",
    "                img_tmp[r + 1, c + 1] = mix_error(img_tmp[r + 1, c + 1], quant_error, 5 / 16)\n",
    "            \n",
    "            # Apply dithering\n",
    "            dithering[r, c] = new_pixel\n",
    "    return dithering\n",
    "\n",
    "\n",
    "quantize_bw = ft.partial(apply_quantization, palette=np.array([[0, 0, 0], [255, 255, 255]]))\n",
    "\n",
    "bw_img = dither_image(img, quantize_bw)\n",
    "plt.imshow(bw_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Points\n",
    "\n",
    "Repeat the homework using a diffrerent image pallette. For instance, you can use an optimal colour\n",
    "pallette that we can calculate via k-means algorithm. The following snippet of code will give you the 16\n",
    "optimal colours for your original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=16).fit(np.reshape(img, (-1, 3)))\n",
    "colors = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_quantization_color(pixel, palette):\n",
    "    pixel = pixel.astype(np.float32)\n",
    "    min_diff = np.inf\n",
    "    selected_color = None\n",
    "    \n",
    "    for c in palette:\n",
    "        diff_sq = (c[0] - pixel[0]) ** 2 + (c[1] - pixel[1]) ** 2 + (c[2] - pixel[2]) ** 2\n",
    "        if diff_sq < min_diff:\n",
    "            min_diff = diff_sq\n",
    "            selected_color = c\n",
    "\n",
    "    return selected_color\n",
    "\n",
    "quantize_km = ft.partial(apply_quantization_color, palette=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dither_image(img, quantize_km));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply FS dithering the same way you did before.\n",
    "* How does the result look like to you?\n",
    "* What happens if we use 32 colours?\n",
    "* And what happens if we use 256 colours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dither_km(img, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters).fit(np.reshape(img, (-1, 3)))\n",
    "    colors = kmeans.cluster_centers_\n",
    "    \n",
    "    quantize_km = ft.partial(apply_quantization_color, palette=colors)\n",
    "    return dither_image(img, quantize_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dither_km(img, 32));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dither_km(img, 256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
